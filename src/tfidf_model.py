# -*- coding: utf-8 -*-
"""Use tfidf to extract the text feature;
The text feature include page title and page text.
"""
import os
import numpy as np
import pandas as pd

from sklearn.feature_extraction.text import  TfidfVectorizer

from utility import write_to_file,load_model,save_model
from conf import STORAGE

def load_documents(document_save_path):
    
    dataset = pd.read_csv(document_save_path,names=['file_id','label','txt'],nrows = None)
    
    labels = []
    docs = []
    
    for index,row in dataset.iterrows():
        label = row['label']
        content = row['txt']

        labels.append(int(label))
        docs.append(content)
        
    return labels,docs

def load_test_documents(document_save_path):
    
    dataset = pd.read_csv(document_save_path,names=['file_id','txt'],nrows = None)
    
    labels = []
    docs = []
    filesid=[]
    
    for index,row in dataset.iterrows():
#         label = row['lable']
        content = row['txt']
        fileid = row['file_id']
        labels.append(-1)
        docs.append(content)
        filesid.append(fileid)
        
    return labels,docs,filesid

def display_scores(vectorizer, tfidf_result,savesubfolder):
    # http://stackoverflow.com/questions/16078015/
    
    write_to_file(os.path.join(STORAGE,'{}/webpage.vocabulary.txt'.format(savesubfolder)), b'','wb+')
    for fea_name in vectorizer.get_feature_names():
        fea_name=fea_name+'\n'
        write_to_file(os.path.join(STORAGE,'{}/webpage.vocabulary.txt'.format(savesubfolder)), fea_name.encode('utf-8'))
        
    scores = zip(vectorizer.get_feature_names(),
                 np.asarray(tfidf_result.sum(axis=0)).ravel())
    
    sorted_scores = sorted(scores, key=lambda x: x[1], reverse=True)
    
    index = 0
    write_to_file(os.path.join(STORAGE,'{}/webpage.vocabulary_top.txt'.format(savesubfolder)), b'','wb+')
    for item in sorted_scores:
        index+=1
        txt = "{0} {1:50} Score: {2}\n".format(index,repr(item[0]), item[1])    
        write_to_file(os.path.join(STORAGE,'{}/webpage.vocabulary_top.txt'.format(savesubfolder)), txt.encode('utf-8'))        
        
        
def api_call_tfidf():
    
    document_title_content_save_path=os.path.join(STORAGE,'apicall.txt')
    test_document_title_content_save_path=os.path.join(STORAGE,'test_apicall.txt')
    
    tfidf_save_path = os.path.join(STORAGE,'apicall_tfidf/webpage.tfidf.model')

    rawy ,raw_documents = load_documents(document_title_content_save_path)
    labels,docs,filesid = load_test_documents(test_document_title_content_save_path)
    
    documents=raw_documents+docs
    
    print(len(documents),len(documents))
          
#   model = TfidfVectorizer(min_df = 4,decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=50000)
    model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(2, 3),max_features=5000)  #apicall
#     model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=1500) 
     
    x = model.fit_transform(documents)
    
    save_model(model,tfidf_save_path)
    
    display_scores(model,x,'apicall_tfidf')
    
def api_type_tfidf():
    
    
    test_document_title_content_save_path=os.path.join(STORAGE,'test_apicall.type.txt')
    document_title_content_save_path=os.path.join(STORAGE,'apicall.type.txt')

    
    
    tfidf_save_path = os.path.join(STORAGE,'api_type_tfidf/webpage.tfidf.model')

    rawy ,raw_documents = load_documents(document_title_content_save_path)
    labels,docs,filesid = load_test_documents(test_document_title_content_save_path)
    
    documents=raw_documents+docs
    
    print(len(documents),len(documents))
          
#   model = TfidfVectorizer(min_df = 4,decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=50000)
    model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(4, 5),max_features=2000)  #apicall
#     model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=1500) 
     
    x = model.fit_transform(documents)
    
    save_model(model,tfidf_save_path)
    
    display_scores(model,x,'api_type_tfidf')
    
def api_type_tfidf_5():
    
    
    test_document_title_content_save_path=os.path.join(STORAGE,'test_apicall.type.txt')
    document_title_content_save_path=os.path.join(STORAGE,'apicall.type.txt')
    
    tfidf_save_path = os.path.join(STORAGE,'api_type_tfidf_5/webpage.tfidf.model')

    rawy ,raw_documents = load_documents(document_title_content_save_path)
    labels,docs,filesid = load_test_documents(test_document_title_content_save_path)
    
    documents=raw_documents+docs
    
    print(len(documents),len(documents))
          
#   model = TfidfVectorizer(min_df = 4,decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=50000)
    model = TfidfVectorizer(min_df = 3,decode_error ='ignore',stop_words='english',ngram_range=(5, 5),max_features=1000)  #apicall
#     model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=1500) 
     
    x = model.fit_transform(documents)
    
    save_model(model,tfidf_save_path)
    
    display_scores(model,x,'api_type_tfidf_5')
def api_call_tfidf_1():
    
    document_title_content_save_path=os.path.join(STORAGE,'apicall.txt')
    test_document_title_content_save_path=os.path.join(STORAGE,'test_apicall.txt')
    
    tfidf_save_path = os.path.join(STORAGE,'apicall_tfidf_1/webpage.tfidf.model')

    rawy ,raw_documents = load_documents(document_title_content_save_path)
    labels,docs,filesid = load_test_documents(test_document_title_content_save_path)
    
    documents=raw_documents+docs
  
    model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(1, 1)) 
     
    x = model.fit_transform(documents)
    
    save_model(model,tfidf_save_path)
    
    display_scores(model,x,'apicall_tfidf_1')
    
def rtnvalue_api_call_tfidf():
    
    document_title_content_save_path=os.path.join(STORAGE,'rtnvalue_apicall.txt')
    test_document_title_content_save_path=os.path.join(STORAGE,'test_rtnvalue_apicall.txt')
    
    tfidf_save_path = os.path.join(STORAGE,'rtn_apicall_tfidf/webpage.tfidf.model')

    rawy ,raw_documents = load_documents(document_title_content_save_path)
    labels,docs,filesid = load_test_documents(test_document_title_content_save_path)
    
    documents=raw_documents+docs
    
    print(len(documents),len(documents))
          
#   model = TfidfVectorizer(min_df = 4,decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=50000)
#     model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(2, 3),max_features=5000)  #apicall
    model = TfidfVectorizer(decode_error ='ignore',stop_words='english',ngram_range=(1, 1),max_features=1500) 
     
    x = model.fit_transform(documents)
    
    save_model(model,tfidf_save_path)
    
    display_scores(model,x,'rtn_apicall_tfidf')
    
def rtnvalue__tfidf():
    
    document_title_content_save_path=os.path.join(STORAGE,'rtvalue.txt')
    test_document_title_content_save_path=os.path.join(STORAGE,'test_rtvalue.txt')   
    
    tfidf_save_path = os.path.join(STORAGE,'rtnvalue_tfidf/webpage.tfidf.model')

    rawy ,raw_documents = load_documents(document_title_content_save_path)
    labels,docs,filesid = load_test_documents(test_document_title_content_save_path)
    
    documents=raw_documents+docs
    
    print(len(documents),len(documents))

    model = TfidfVectorizer(min_df = 4,decode_error ='ignore',stop_words='english',ngram_range=(1, 3),max_features=3000) 
     
    x = model.fit_transform(documents)
    
    save_model(model,tfidf_save_path)
    
    display_scores(model,x,'rtnvalue_tfidf')
    
    
def main():    

    api_type_tfidf_5()
    api_call_tfidf_1()
    api_call_tfidf()
    rtnvalue_api_call_tfidf()
    rtnvalue__tfidf()

if __name__ == "__main__":

    main()

                
                
        
        
        